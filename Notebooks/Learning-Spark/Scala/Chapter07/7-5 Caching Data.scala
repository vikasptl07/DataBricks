// Databricks notebook source
// MAGIC 
// MAGIC %md
// MAGIC # Caching Data

// COMMAND ----------

// MAGIC %md
// MAGIC ### Use _cache()_

// COMMAND ----------

// MAGIC %md
// MAGIC Create a large data set with couple of columns

// COMMAND ----------

val df = spark.range(1 * 10000000).toDF("id").withColumn("square", $"id" * $"id")
df.cache().count()

// COMMAND ----------

df.count()

// COMMAND ----------

// MAGIC %md
// MAGIC Check the Spark UI storage tab to see where the data is stored.

// COMMAND ----------

df.unpersist() // If you do not unpersist, df2 below will not be cached because it has the same query plan as df

// COMMAND ----------

// MAGIC %md
// MAGIC ### Use _persist(StorageLevel.Level)_

// COMMAND ----------

import org.apache.spark.storage.StorageLevel

val df2 = spark.range(1 * 10000000).toDF("id").withColumn("square", $"id" * $"id")
df2.persist(StorageLevel.DISK_ONLY).count()

// COMMAND ----------

df2.count()

// COMMAND ----------

// MAGIC %md
// MAGIC Check the Spark UI storage tab to see where the data is stored

// COMMAND ----------

df2.unpersist()

// COMMAND ----------

df.createOrReplaceTempView("dfTable")
spark.sql("CACHE TABLE dfTable")

// COMMAND ----------

// MAGIC %md
// MAGIC Check the Spark UI storage tab to see where the data is stored.

// COMMAND ----------

spark.sql("SELECT count(*) FROM dfTable").show()

